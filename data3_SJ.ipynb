{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1- Dataset introduction\n",
    "This dataset is called default of credit card clients found at UCI which can be accessed using the following link-\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "It contains default payments of customers in Taiwan.\n",
    "It has 30,000 instances and 24 attributes along with a target Y which has 0 or 1 values stating the default payment due next month (if yes, it is 1 otherwise 0).\n",
    "The attributes characteristic are Integer, Real. \n",
    "\n",
    "\n",
    "Attribute information is as follows-\n",
    "\n",
    "\n",
    "default value (Yes=1, No=0) is the response or target variable. \n",
    "\n",
    "All other 23 variables are-\n",
    "X1: Amount of the given credit\n",
    "X2: Gender (1 = male; 2 = female)\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others)\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others)\n",
    "X5: Age (year)\n",
    "X6 - X11: History of past payment. \n",
    "  X6 = the repayment status in September, 2005 \n",
    "  X7 = the repayment status in August, 2005 . . .X11= the repayment status in April, 2005. \n",
    "  \n",
    "    The measurement scale for the repayment status is: \n",
    "    -1 = pay duly\n",
    "    1 = payment delay for one month \n",
    "    2 = payment delay for two months; . . .; 8 = payment delay for eight months\n",
    "    9 = payment delay for nine months and above\n",
    "\n",
    "\n",
    "X12-X17: Amount of bill statement\n",
    "    X12 = amount of bill statement in September, 2005\n",
    "    X13 = amount of bill statement in August, 2005; . . . X17 = amount of bill statement in April, 2005.\n",
    "\n",
    "X18-X23: Amount of previous payment \n",
    "    X18 = amount paid in September, 2005\n",
    "    X19 = amount paid in August, 2005 . . .X23 = amount paid in April, 2005. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2- Loading the dataset\n",
    "In this section , I am loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data set is (No of instances, No of atttributes) =  (30000, 25)\n",
      "\n",
      "\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "\n",
      "              ...              BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
      "0             ...                      0          0          0         0   \n",
      "1             ...                   3272       3455       3261         0   \n",
      "2             ...                  14331      14948      15549      1518   \n",
      "3             ...                  28314      28959      29547      2000   \n",
      "\n",
      "   PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
      "0       689         0         0         0         0   \n",
      "1      1000      1000      1000         0      2000   \n",
      "2      1500      1000      1000      1000      5000   \n",
      "3      2019      1200      1100      1069      1000   \n",
      "\n",
      "   default payment next month  \n",
      "0                           1  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "\n",
      "[4 rows x 25 columns]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import graphviz \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "ST_data=pd.read_csv('/Users/shomronjacob/Desktop/default of credit card clients.csv')\n",
    "print(\"The shape of the data set is (No of instances, No of atttributes) = \",ST_data.shape )\n",
    "# print(ST_data.shape)\n",
    "print('')\n",
    "print('')\n",
    "print(ST_data.head(4))\n",
    "feature_names=[\"ID\",\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_1\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"deafault payment next month\"]\n",
    "target_names=[\"No\",\"Yes\"]\n",
    "leg_fn=len(feature_names)\n",
    "print(leg_fn)\n",
    "dataset=pd.DataFrame(ST_data,columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3- Spliting the dataset\n",
    "\n",
    "This section deals with spliting of the dataset into test and train using the train_test_split from sklearn.\n",
    "The ration taken is 2/3 for train and 1/3 for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "     ...     BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
      "0    ...           689          0          0          0         0       689   \n",
      "1    ...          2682       3272       3455       3261         0      1000   \n",
      "2    ...         13559      14331      14948      15549      1518      1500   \n",
      "3    ...         49291      28314      28959      29547      2000      2019   \n",
      "4    ...         35835      20940      19146      19131      2000     36681   \n",
      "\n",
      "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
      "0         0         0         0         0  \n",
      "1      1000      1000         0      2000  \n",
      "2      1000      1000      1000      5000  \n",
      "3      1200      1100      1069      1000  \n",
      "4     10000      9000       689       679  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "\n",
      "0        1\n",
      "1        1\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9        0\n",
      "10       0\n",
      "11       0\n",
      "12       0\n",
      "13       1\n",
      "14       0\n",
      "15       0\n",
      "16       1\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       1\n",
      "22       1\n",
      "23       1\n",
      "24       0\n",
      "25       0\n",
      "26       1\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "        ..\n",
      "29970    0\n",
      "29971    0\n",
      "29972    0\n",
      "29973    1\n",
      "29974    1\n",
      "29975    0\n",
      "29976    1\n",
      "29977    0\n",
      "29978    0\n",
      "29979    0\n",
      "29980    0\n",
      "29981    0\n",
      "29982    1\n",
      "29983    0\n",
      "29984    0\n",
      "29985    0\n",
      "29986    0\n",
      "29987    0\n",
      "29988    0\n",
      "29989    0\n",
      "29990    0\n",
      "29991    1\n",
      "29992    0\n",
      "29993    0\n",
      "29994    1\n",
      "29995    0\n",
      "29996    0\n",
      "29997    1\n",
      "29998    1\n",
      "29999    1\n",
      "Name: default payment next month, Length: 30000, dtype: int64\n",
      "(30000, 24)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "X=ST_data.iloc[:,0:24]\n",
    "Y=ST_data.iloc[:,24]\n",
    "print(X.head(5))\n",
    "print('')\n",
    "print('')\n",
    "print(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "\n",
      "     ...     BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
      "0    ...           689          0          0          0         0       689   \n",
      "1    ...          2682       3272       3455       3261         0      1000   \n",
      "2    ...         13559      14331      14948      15549      1518      1500   \n",
      "3    ...         49291      28314      28959      29547      2000      2019   \n",
      "\n",
      "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
      "0         0         0         0         0  \n",
      "1      1000      1000         0      2000  \n",
      "2      1000      1000      1000      5000  \n",
      "3      1200      1100      1069      1000  \n",
      "\n",
      "[4 rows x 24 columns]\n",
      "\n",
      "\n",
      "\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "Name: default payment next month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.333, random_state=42, shuffle=False)\n",
    "print(X_train.head(4))\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print(y_train.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4- Model fitting \n",
    "Here, I am fitting the model using Logistic regression. This section has several parts which are divided into sub headings with explanations for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#            # 4.1- L2-regularized model \n",
    "Here, I train the L2 regularized logistic regression on the train split using default paramenters for all except penalty which is set to L2.\n",
    "After the model is fit, I am printing the top 10 features having highest absolute values of their weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "The score of the model is 77.8733333333\n",
      "Predicted score is- [0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(penalty='l2')\n",
    "model2_lr=model.fit(X_train,y_train)\n",
    "print(model2_lr)\n",
    "# predict class labels for test set\n",
    "print(\"The score of the model is\", model2_lr.score(X,Y)*100)\n",
    "print(\"Predicted score is-\",model2_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight values of the features are: \n",
      " [[ -3.40853741e-05  -3.62339701e-06  -7.68244258e-05  -9.25598163e-05\n",
      "   -8.85366171e-05  -1.21810076e-03   2.19698169e-04   1.71294370e-04\n",
      "    1.53060659e-04   1.38204597e-04   1.30368087e-04   1.16918699e-04\n",
      "   -1.21737566e-05   7.19495423e-06   9.27261392e-07   2.39841111e-06\n",
      "    4.59939806e-06   1.33663565e-06  -3.98586998e-05  -1.66657324e-05\n",
      "   -9.33034489e-06  -1.08053968e-05  -2.32712701e-06  -2.11777689e-06]]\n"
     ]
    }
   ],
   "source": [
    "# printing weights of the features\n",
    "print(\"Weight values of the features are: \\n\",model2_lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.80437278e-05   2.77603963e-06   2.58043024e-03   2.40567336e-03\n",
      "   3.32240605e-03   1.04421884e-02   1.25634225e-02   9.68672105e-03\n",
      "   8.61463608e-03   7.60405570e-03   7.15541785e-03   6.36271739e-03\n",
      "   1.09025598e-05   6.71538389e-06   1.02376787e-06   1.29876265e-06\n",
      "   4.67044181e-06   1.13811466e-06   3.57969815e-05   1.51150767e-05\n",
      "   8.37727458e-06   1.02678520e-05   2.05226525e-06   2.36324481e-06]\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  7,  8,  9, 10, 11,  4,  2,  3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the above calculated coef(weight) values and the get the absolute values\n",
    "weights=model2_lr.coef_[0]\n",
    "weights_absolute=np.abs(weights)\n",
    "print(weights_absolute)\n",
    "print(len(weights_absolute))\n",
    "# sorting absolute weights to get top 10 features\n",
    "sortted_weights=np.argsort(weights_absolute)[::-1][:10]\n",
    "sortted_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4.1.1- Top 10 features\n",
    "Here, the top 10 features along with the weights (absolute values) are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features (after L2 regularization) along with their weights are-\n",
      "\n",
      "PAY_0 0.012563422511\n",
      "AGE 0.0104421884498\n",
      "PAY_1 0.00968672105435\n",
      "PAY_2 0.00861463607824\n",
      "PAY_3 0.00760405570222\n",
      "PAY_4 0.00715541785189\n",
      "BILL_AMT1 0.00636271738548\n",
      "MARRIAGE 0.00332240605121\n",
      "SEX 0.00258043023871\n",
      "EDUCATION 0.00240567335777\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 features (after L2 regularization) along with their weights are-\")\n",
    "print('')\n",
    "for i in sortted_weights:\n",
    "    print(feature_names[i] , weights_absolute[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2- L1 regularization\n",
    "here, I train the model using L1 regularization with penalty as L1. Same as above, the top 10 features are also shown along with their absolute weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "The score of the model is 81.0266666667\n",
      "Predicted score is- [0 0 0 ..., 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "model1=LogisticRegression(penalty='l1')\n",
    "model1_lr=model1.fit(X_train,y_train)\n",
    "print(model1_lr)\n",
    "print('')\n",
    "print(\"The score of the model is\", model1_lr.score(X,Y)*100)\n",
    "print(\"Predicted score is-\",model1_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight values of the features are: \n",
      " [[  2.16225733e-07  -5.65469467e-07  -9.27901561e-02  -1.09588837e-01\n",
      "   -1.63739121e-01   4.48776279e-03   5.70106799e-01   6.82712031e-02\n",
      "    8.37148941e-02  -1.09115117e-02   8.24060192e-02  -7.40228419e-03\n",
      "   -7.01283557e-06   3.63955364e-06   2.42895781e-07  -5.83037919e-07\n",
      "    2.22214697e-06   3.88902915e-07  -1.73937597e-05  -6.50418557e-06\n",
      "   -3.69610091e-06  -4.96801504e-06  -8.60934591e-07  -2.31113433e-06]]\n"
     ]
    }
   ],
   "source": [
    "# printing weights of the features\n",
    "print(\"Weight values of the features are: \\n\",model1_lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.37722742e-07   5.64491657e-07   9.23206756e-02   1.09370253e-01\n",
      "   1.62918145e-01   4.53585272e-03   5.70113679e-01   6.82825936e-02\n",
      "   8.37574226e-02   1.08722478e-02   8.24218825e-02   7.46707935e-03\n",
      "   6.99320618e-06   3.60145682e-06   2.82921466e-07   6.56528205e-07\n",
      "   2.31533463e-06   3.47592146e-07   1.73675273e-05   6.52807206e-06\n",
      "   3.67167648e-06   5.02201716e-06   8.25846348e-07   2.31801479e-06]\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6,  4,  3,  2,  8, 10,  7,  9, 11,  5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the above calculated coef(weight) values and the get the absolute values\n",
    "weights_L1=model1_lr.coef_[0]\n",
    "weights_absolute_L1=np.abs(weights_L1)\n",
    "print(weights_absolute_L1)\n",
    "print(len(weights_absolute_L1))\n",
    "# sorting absolute weights to get top 10 features\n",
    "sortted_weights_L1=np.argsort(weights_absolute_L1)[::-1][:10]\n",
    "sortted_weights_L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.1- Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features (after L1 regularization) along with their weights are-\n",
      "\n",
      "PAY_0 0.570113678845\n",
      "MARRIAGE 0.162918144984\n",
      "EDUCATION 0.109370253373\n",
      "SEX 0.0923206755864\n",
      "PAY_2 0.0837574226444\n",
      "PAY_4 0.0824218824757\n",
      "PAY_1 0.0682825936383\n",
      "PAY_3 0.0108722477881\n",
      "BILL_AMT1 0.00746707935113\n",
      "AGE 0.00453585271719\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 features (after L1 regularization) along with their weights are-\")\n",
    "print('')\n",
    "for j in sortted_weights_L1:\n",
    "    print(feature_names[j] , weights_absolute_L1[j] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Decision tree classifier\n",
    "This section trains the DecisionTreeClassifier on the train split using max_depth=6 and min_impurity_decrease=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.005, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"390pt\" height=\"300pt\"\n",
       " viewBox=\"0.00 0.00 390.27 300.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 296)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-296 386.2715,-296 386.2715,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.705882\" stroke=\"#000000\" d=\"M297.0864,-292C297.0864,-292 169.9712,-292 169.9712,-292 163.9712,-292 157.9712,-286 157.9712,-280 157.9712,-280 157.9712,-226 157.9712,-226 157.9712,-220 163.9712,-214 169.9712,-214 169.9712,-214 297.0864,-214 297.0864,-214 303.0864,-214 309.0864,-220 309.0864,-226 309.0864,-226 309.0864,-280 309.0864,-280 309.0864,-286 303.0864,-292 297.0864,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">PAY_0 &lt;= 1.5</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.352</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20010</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [15450, 4560]</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.792157\" stroke=\"#000000\" d=\"M217.0864,-178C217.0864,-178 89.9712,-178 89.9712,-178 83.9712,-178 77.9712,-172 77.9712,-166 77.9712,-166 77.9712,-112 77.9712,-112 77.9712,-106 83.9712,-100 89.9712,-100 89.9712,-100 217.0864,-100 217.0864,-100 223.0864,-100 229.0864,-106 229.0864,-112 229.0864,-112 229.0864,-166 229.0864,-166 229.0864,-172 223.0864,-178 217.0864,-178\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">PAY_1 &lt;= 1.5</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.284</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17814</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [14759, 3055]</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M205.9973,-213.7677C199.8378,-204.9903 193.2399,-195.5883 186.8735,-186.5161\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.7203,-184.4797 181.111,-178.3046 183.9904,-188.5007 189.7203,-184.4797\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.7954\" y=\"-198.7293\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.541176\" stroke=\"#000000\" d=\"M370.515,-171C370.515,-171 258.5426,-171 258.5426,-171 252.5426,-171 246.5426,-165 246.5426,-159 246.5426,-159 246.5426,-119 246.5426,-119 246.5426,-113 252.5426,-107 258.5426,-107 258.5426,-107 370.515,-107 370.515,-107 376.515,-107 382.515,-113 382.515,-119 382.515,-119 382.515,-159 382.515,-159 382.515,-165 376.515,-171 370.515,-171\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.431</text>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2196</text>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [691, 1505]</text>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261.4044,-213.7677C269.2813,-202.6817 277.8661,-190.5994 285.7925,-179.4436\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.764,-181.3043 291.703,-171.1252 283.0578,-177.2498 288.764,-181.3043\"/>\n",
       "<text text-anchor=\"middle\" x=\"295.8745\" y=\"-191.5747\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.827451\" stroke=\"#000000\" d=\"M139.0864,-64C139.0864,-64 11.9712,-64 11.9712,-64 5.9712,-64 -.0288,-58 -.0288,-52 -.0288,-52 -.0288,-12 -.0288,-12 -.0288,-6 5.9712,0 11.9712,0 11.9712,0 139.0864,0 139.0864,0 145.0864,0 151.0864,-6 151.0864,-12 151.0864,-12 151.0864,-52 151.0864,-52 151.0864,-58 145.0864,-64 139.0864,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.253</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16250</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [13840, 2410]</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M124.9274,-99.7647C118.4694,-90.9057 111.6011,-81.4838 105.104,-72.571\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.733,-70.236 99.014,-64.2169 102.0764,-74.3595 107.733,-70.236\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.298039\" stroke=\"#000000\" d=\"M284.2284,-64C284.2284,-64 180.8292,-64 180.8292,-64 174.8292,-64 168.8292,-58 168.8292,-52 168.8292,-52 168.8292,-12 168.8292,-12 168.8292,-6 174.8292,0 180.8292,0 180.8292,0 284.2284,0 284.2284,0 290.2284,0 296.2284,-6 296.2284,-12 296.2284,-12 296.2284,-52 296.2284,-52 296.2284,-58 290.2284,-64 284.2284,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.485</text>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1564</text>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [919, 645]</text>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.4969,-99.7647C189.1051,-90.8144 196.1375,-81.2894 202.7779,-72.2955\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"205.6185,-74.3407 208.7425,-64.2169 199.9871,-70.1829 205.6185,-74.3407\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1134ed198>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(max_depth=6,min_impurity_decrease=0.005)\n",
    "clf=clf.fit(X_train,y_train)\n",
    "print(clf)\n",
    "dot_data=tree.export_graphviz(clf,feature_names=feature_names,class_names=target_names,filled=True,rounded=True,out_file=None)\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4- Discussion of results?\n",
    "If you look at the top 10 feature results of L1 and L2 and compare that with DT, you will notice that L2 and Dt show some features that are common between the two, however there is no feature from L1 that comes up in DT, hence L2 and DT provide more details and work close to each other while L1 does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5- Z-scoring all features using StandardScaler\n",
    "This deals with z-scoring all features using StandardScaler. Both test and train are also z-scored using the same. then I use fit_transform on train and transform.fit on test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scaled train data is: \n",
      " [[-1.73196425 -1.11327836  0.79247745 ..., -0.3113011  -0.30806408\n",
      "  -0.29353309]\n",
      " [-1.73179113 -0.33658165  0.79247745 ..., -0.24540989 -0.30806408\n",
      "  -0.17794172]\n",
      " [-1.73161801 -0.56959066  0.79247745 ..., -0.24540989 -0.24331108\n",
      "  -0.00455468]\n",
      " ..., \n",
      " [ 1.73161801  0.12943638  0.79247745 ..., -0.27321598 -0.27970226\n",
      "  -0.27735029]\n",
      " [ 1.73179113  0.28477572  0.79247745 ..., -0.11362747 -0.09871762\n",
      "  -0.12014604]\n",
      " [ 1.73196425  0.51778474  0.79247745 ..., -0.22933244 -0.30806408\n",
      "  -0.24677638]]\n",
      "\n",
      "\n",
      "Scaled test data is: \n",
      " [[ 1.73213737  0.36244539  0.79247745 ..., -0.08068187  0.00799532\n",
      "  -0.08090277]\n",
      " [ 1.73231049  0.05176671  0.79247745 ...,  0.09241434  0.11606808\n",
      "   0.05902058]\n",
      " [ 1.73248361  0.28477572  0.79247745 ...,  1.22785167  1.35692985\n",
      "   0.27771944]\n",
      " ..., \n",
      " [ 3.46107205 -1.03560869 -1.26186556 ..., -0.03455802 -0.17855807\n",
      "  -0.11436647]\n",
      " [ 3.46124516 -0.64726033 -1.26186556 ..., -0.18439463  3.12151389\n",
      "  -0.18926968]\n",
      " [ 3.46141828 -0.88026935 -1.26186556 ..., -0.24540989 -0.24331108\n",
      "  -0.2357374 ]]\n"
     ]
    }
   ],
   "source": [
    "# creating a scalar object\n",
    "sc=StandardScaler()\n",
    "\n",
    "#Fitting the scalar to the training data and transfrom\n",
    "X_train_std=sc.fit_transform(X_train)\n",
    "\n",
    "X_test_std=sc.transform(X_test)\n",
    "print(\"The scaled train data is: \\n\",X_train_std)\n",
    "print('')\n",
    "print('')\n",
    "print(\"Scaled test data is: \\n\",X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.73196425 -1.11327836  0.79247745 ..., -0.3113011  -0.30806408\n",
      "  -0.29353309]\n",
      " [-1.73179113 -0.33658165  0.79247745 ..., -0.24540989 -0.30806408\n",
      "  -0.17794172]\n",
      " [-1.73161801 -0.56959066  0.79247745 ..., -0.24540989 -0.24331108\n",
      "  -0.00455468]\n",
      " ..., \n",
      " [ 1.73161801  0.12943638  0.79247745 ..., -0.27321598 -0.27970226\n",
      "  -0.27735029]\n",
      " [ 1.73179113  0.28477572  0.79247745 ..., -0.11362747 -0.09871762\n",
      "  -0.12014604]\n",
      " [ 1.73196425  0.51778474  0.79247745 ..., -0.22933244 -0.30806408\n",
      "  -0.24677638]]\n"
     ]
    }
   ],
   "source": [
    "# creating the pickle file for my data\n",
    "A = {}\n",
    "A['X_train'] = X_train_std\n",
    "A['y_train'] = y_train\n",
    "A['X_test'] = X_test_std\n",
    "A['y_test'] = y_test\n",
    "A['target_names'] = target_names\n",
    "A['feature_names'] = feature_names\n",
    "pickle.dump(A, open(\"sjacob9.pickle\", \"wb\"))\n",
    "print(A['X_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5.1- Repeating 4.1 to 4.3 on above z-scored data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 regularisation using penalty as l2 (z-scored data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "The score of the model is 77.77\n",
      "Predicted score is- [0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_stdL2=LogisticRegression(penalty='l2')\n",
    "model2_lr_std=model_stdL2.fit(X_train_std,y_train)\n",
    "print(model2_lr_std)\n",
    "print('')\n",
    "# predict class labels for test set\n",
    "print(\"The score of the model is\", model2_lr_std.score(X,Y)*100)\n",
    "print(\"Predicted score is-\",model_stdL2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight values of the features are: \n",
      " [[ 0.00195904 -0.07227527 -0.04432946 -0.08388282 -0.08398006  0.04341904\n",
      "   0.6394942   0.08243452  0.10250346 -0.01472419  0.09630477 -0.01002737\n",
      "  -0.49470989  0.24581852  0.01668352 -0.03702786  0.13303432  0.02246292\n",
      "  -0.2631305  -0.13951047 -0.05872348 -0.07536339 -0.01333948 -0.04003837]]\n"
     ]
    }
   ],
   "source": [
    "#feature weights are\n",
    "print(\"Weight values of the features are: \\n\",model2_lr_std.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00195904  0.07227527  0.04432946  0.08388282  0.08398006  0.04341904\n",
      "  0.6394942   0.08243452  0.10250346  0.01472419  0.09630477  0.01002737\n",
      "  0.49470989  0.24581852  0.01668352  0.03702786  0.13303432  0.02246292\n",
      "  0.2631305   0.13951047  0.05872348  0.07536339  0.01333948  0.04003837]\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6, 12, 18, 13, 19, 16,  8, 10,  4,  3])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the above calculated coef(weight) values and the get the absolute values\n",
    "weights_std_L2=model2_lr_std.coef_[0]\n",
    "weights_absolute_std_L2=np.abs(weights_std_L2)\n",
    "print(weights_absolute_std_L2)\n",
    "print(len(weights_absolute_std_L2))\n",
    "# sorting absolute weights to get top 10 features\n",
    "sortted_weights_std_L2=np.argsort(weights_absolute_std_L2)[::-1][:10]\n",
    "sortted_weights_std_L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features on z-scored data (after L2 regularization) along with their weights are-\n",
      "\n",
      "PAY_0 0.639494203853\n",
      "BILL_AMT2 0.494709892941\n",
      "PAY_AMT2 0.263130498762\n",
      "BILL_AMT3 0.245818515394\n",
      "PAY_AMT3 0.139510466035\n",
      "BILL_AMT6 0.133034323329\n",
      "PAY_2 0.102503463155\n",
      "PAY_4 0.0963047674867\n",
      "MARRIAGE 0.0839800584923\n",
      "EDUCATION 0.0838828192747\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 features on z-scored data (after L2 regularization) along with their weights are-\")\n",
    "print('')\n",
    "for k in sortted_weights_std_L2:\n",
    "    print(feature_names[k] , weights_absolute_std_L2[k] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 regularisation using penalty l1 (z-scored data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "The score of the model is 77.82\n",
      "Predicted score is- [0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model1_stdL1=LogisticRegression(penalty='l1')\n",
    "model1_lr_std_L1=model1_stdL1.fit(X_train_std,y_train)\n",
    "print(model1_lr_std_L1)\n",
    "print('')\n",
    "print(\"The score of the model is\", model1_lr_std_L1.score(X,Y)*100)\n",
    "print(\"Predicted score is-\",model1_lr_std_L1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00131391 -0.07214678 -0.04403678 -0.0833661  -0.08367381  0.04316827\n",
      "   0.63984263  0.08208739  0.10167319 -0.01251092  0.09366534 -0.00802268\n",
      "  -0.47998978  0.23298278  0.0046129  -0.0128101   0.12042772  0.01993581\n",
      "  -0.25977888 -0.13832346 -0.06094201 -0.07220359 -0.01277716 -0.03988877]]\n"
     ]
    }
   ],
   "source": [
    "# Feature weights are\n",
    "print(model1_lr_std_L1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00131391  0.07214678  0.04403678  0.0833661   0.08367381  0.04316827\n",
      "  0.63984263  0.08208739  0.10167319  0.01251092  0.09366534  0.00802268\n",
      "  0.47998978  0.23298278  0.0046129   0.0128101   0.12042772  0.01993581\n",
      "  0.25977888  0.13832346  0.06094201  0.07220359  0.01277716  0.03988877]\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6, 12, 18, 13, 19, 16,  8, 10,  4,  3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the above calculated coef(weight) values and the get the absolute values\n",
    "weights_L1_std=model1_lr_std_L1.coef_[0]\n",
    "weights_absolute_std_L1=np.abs(weights_L1_std)\n",
    "print(weights_absolute_std_L1)\n",
    "print(len(weights_absolute_std_L1))\n",
    "# sorting absolute weights to get top 10 features\n",
    "sortted_weights_std_L1=np.argsort(weights_absolute_std_L1)[::-1][:10]\n",
    "sortted_weights_std_L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features on z-scored data (after L1 regularization) along with their weights are-\n",
      "\n",
      "PAY_0 0.639842629203\n",
      "BILL_AMT2 0.479989778473\n",
      "PAY_AMT2 0.259778878986\n",
      "BILL_AMT3 0.232982780018\n",
      "PAY_AMT3 0.138323458952\n",
      "BILL_AMT6 0.120427718762\n",
      "PAY_2 0.101673192088\n",
      "PAY_4 0.0936653426071\n",
      "MARRIAGE 0.0836738093597\n",
      "EDUCATION 0.0833661006358\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 features on z-scored data (after L1 regularization) along with their weights are-\")\n",
    "print('')\n",
    "for m in sortted_weights_std_L1:\n",
    "    print(feature_names[m] , weights_absolute_std_L1[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisiontreeclassifier (z-scored data)\n",
    "max_depth=6 and min_impurity_decrease=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.005, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"390pt\" height=\"300pt\"\n",
       " viewBox=\"0.00 0.00 390.27 300.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 296)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-296 386.2715,-296 386.2715,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.705882\" stroke=\"#000000\" d=\"M297.0864,-292C297.0864,-292 169.9712,-292 169.9712,-292 163.9712,-292 157.9712,-286 157.9712,-280 157.9712,-280 157.9712,-226 157.9712,-226 157.9712,-220 163.9712,-214 169.9712,-214 169.9712,-214 297.0864,-214 297.0864,-214 303.0864,-214 309.0864,-220 309.0864,-226 309.0864,-226 309.0864,-280 309.0864,-280 309.0864,-286 303.0864,-292 297.0864,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">PAY_0 &lt;= 1.319</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.352</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20010</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [15450, 4560]</text>\n",
       "<text text-anchor=\"middle\" x=\"233.5288\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.792157\" stroke=\"#000000\" d=\"M217.0864,-178C217.0864,-178 89.9712,-178 89.9712,-178 83.9712,-178 77.9712,-172 77.9712,-166 77.9712,-166 77.9712,-112 77.9712,-112 77.9712,-106 83.9712,-100 89.9712,-100 89.9712,-100 217.0864,-100 217.0864,-100 223.0864,-100 229.0864,-106 229.0864,-112 229.0864,-112 229.0864,-166 229.0864,-166 229.0864,-172 223.0864,-178 217.0864,-178\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">PAY_1 &lt;= 1.332</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.284</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17814</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [14759, 3055]</text>\n",
       "<text text-anchor=\"middle\" x=\"153.5288\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M205.9973,-213.7677C199.8378,-204.9903 193.2399,-195.5883 186.8735,-186.5161\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.7203,-184.4797 181.111,-178.3046 183.9904,-188.5007 189.7203,-184.4797\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.7954\" y=\"-198.7293\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.541176\" stroke=\"#000000\" d=\"M370.515,-171C370.515,-171 258.5426,-171 258.5426,-171 252.5426,-171 246.5426,-165 246.5426,-159 246.5426,-159 246.5426,-119 246.5426,-119 246.5426,-113 252.5426,-107 258.5426,-107 258.5426,-107 370.515,-107 370.515,-107 376.515,-107 382.515,-113 382.515,-119 382.515,-119 382.515,-159 382.515,-159 382.515,-165 376.515,-171 370.515,-171\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.431</text>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2196</text>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [691, 1505]</text>\n",
       "<text text-anchor=\"middle\" x=\"314.5288\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261.4044,-213.7677C269.2813,-202.6817 277.8661,-190.5994 285.7925,-179.4436\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.764,-181.3043 291.703,-171.1252 283.0578,-177.2498 288.764,-181.3043\"/>\n",
       "<text text-anchor=\"middle\" x=\"295.8745\" y=\"-191.5747\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.827451\" stroke=\"#000000\" d=\"M139.0864,-64C139.0864,-64 11.9712,-64 11.9712,-64 5.9712,-64 -.0288,-58 -.0288,-52 -.0288,-52 -.0288,-12 -.0288,-12 -.0288,-6 5.9712,0 11.9712,0 11.9712,0 139.0864,0 139.0864,0 145.0864,0 151.0864,-6 151.0864,-12 151.0864,-12 151.0864,-52 151.0864,-52 151.0864,-58 145.0864,-64 139.0864,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.253</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16250</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [13840, 2410]</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5288\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M124.9274,-99.7647C118.4694,-90.9057 111.6011,-81.4838 105.104,-72.571\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.733,-70.236 99.014,-64.2169 102.0764,-74.3595 107.733,-70.236\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.298039\" stroke=\"#000000\" d=\"M284.2284,-64C284.2284,-64 180.8292,-64 180.8292,-64 174.8292,-64 168.8292,-58 168.8292,-52 168.8292,-52 168.8292,-12 168.8292,-12 168.8292,-6 174.8292,0 180.8292,0 180.8292,0 284.2284,0 284.2284,0 290.2284,0 296.2284,-6 296.2284,-12 296.2284,-12 296.2284,-52 296.2284,-52 296.2284,-58 290.2284,-64 284.2284,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.485</text>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1564</text>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [919, 645]</text>\n",
       "<text text-anchor=\"middle\" x=\"232.5288\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.4969,-99.7647C189.1051,-90.8144 196.1375,-81.2894 202.7779,-72.2955\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"205.6185,-74.3407 208.7425,-64.2169 199.9871,-70.1829 205.6185,-74.3407\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x112cd4908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_std=tree.DecisionTreeClassifier(max_depth=6,min_impurity_decrease=0.005)\n",
    "clf_std=clf_std.fit(X_train_std,y_train)\n",
    "print(clf_std)\n",
    "dot_data_std=tree.export_graphviz(clf_std,feature_names=feature_names,class_names=target_names,filled=True,out_file=None,rounded=True)\n",
    "graph_L1_std=graphviz.Source(dot_data_std)\n",
    "graph_L1_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The same process is repeated on z-scored data.In section 4.4,  the top features of L2 and DT matches, but here, after we apply L2, L1 and Dt on the z-scored data, all three of them have the top features which is different from what we observed on section 4.4.\n",
    "Also, the DT matches with same features and same depth as in section 4.4\n",
    "Also, the accuracy of L1 on normal data was 81% which fell to 77% for L1 on z-scored data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5- Evidence on z-scored data\n",
    "In this section, we deal with calculating evidence for the different types of objects-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution is- [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "\n",
      "Predicted probabilty is- [0 0 0 ..., 1 0 0]\n",
      "The bias weight is- -1.41009211603\n",
      "\n",
      "[[ 0.83453188  0.16546812]\n",
      " [ 0.66416518  0.33583482]\n",
      " [ 0.92332598  0.07667402]\n",
      " ..., \n",
      " [ 0.17808544  0.82191456]\n",
      " [ 0.85203616  0.14796384]\n",
      " [ 0.73405019  0.26594981]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shomronjacob/anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# probability distribution \n",
    "probDist=model2_lr_std.predict_proba(X_test)\n",
    "print(\"Probability distribution is-\", probDist)\n",
    "# using predicted probability for L2 on test\n",
    "predProb=model2_lr_std.predict(X_test_std)\n",
    "print('')\n",
    "print(\"Predicted probabilty is-\",predProb)\n",
    "intercept_weight=model2_lr_std.intercept_[0]\n",
    "print(\"The bias weight is-\",intercept_weight)\n",
    "print('')\n",
    "pridprob=model2_lr_std.predict_proba(X_test_std)\n",
    "print(pridprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidence (Positive or Negative)\n",
    "In this section, I am calculating evidence. Based on it being greater than or less than 0 , it is categorised as positive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LR, given D(i), feature X(j) LR calculated as-\n",
    "# LR= W(j)*X(j) over d(i) , here W(j) is for feature value\n",
    "\n",
    "wj_xj=np.multiply(X_test_std,model2_lr_std.coef_[0])\n",
    "\n",
    "evidence_greaterThan0_positive=[] #postive evidence list\n",
    "evidence_lessThan0_negative=[] #negative evidence list\n",
    "LenGTH=X_test_std.shape[0]\n",
    "for j in range(LenGTH):\n",
    "    evidence_greaterThan0_positive.append(np.add(model2_lr_std.intercept_[0],np.sum(k for k in wj_xj[j] if k>0))) # for +ve evidence\n",
    "    evidence_lessThan0_negative.append(np.add(model2_lr_std.intercept_[0],np.sum(k for k in wj_xj[j] if k<0)))    # for -ve evidence        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the final results-\n",
    "def Final(ith):\n",
    "    print(\" Total positive evidence is:\",evidence_greaterThan0_positive[ith])\n",
    "    print('')\n",
    "    print(\" Total negative evidence is:\",evidence_lessThan0_negative[ith])\n",
    "    print('')\n",
    "    print(\"probability distribution is:\", probDist[ith])\n",
    "    print('')\n",
    "    print(\"Object number\",ith,\"is the most positive object\")\n",
    "    evidence=[(j,model2_lr_std.coef_[0][j]*X_test_std[ith][j]) for j in range(leg_fn)]\n",
    "    last3features=sorted(evidence,key=lambda x:x[1])\n",
    "    first3features=sorted(evidence,key=lambda x:-x[1])\n",
    "    print('')\n",
    "    print('')\n",
    "    print(\"Top 3 features for positive log evidence are-\")\n",
    "    L_features=len(feature_names)\n",
    "#     print(L_features)\n",
    "    for j in range(1):\n",
    "        CalE=np.multiply(model2_lr_std.coef_[0][j],X_test_std[ith][j])\n",
    "        for k,CalE in first3features[:3]:\n",
    "            print(\"The feature is-\",feature_names[k],\"having weight_bais_value =\",X_test_std[ith][k],\"and evidence value of\",CalE)\n",
    "        print('')\n",
    "        for k,CalE in last3features[:3]:\n",
    "            print(\"The feature is-\",feature_names[k],\"having weight_bais_value =\" ,X_test_std[ith][k],\"and evidence value of\",CalE)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1- The most positive object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total positive evidence is: 0.351328650118\n",
      "\n",
      " Total negative evidence is: -7.44389639915\n",
      "\n",
      "probability distribution is: [ 0.  1.]\n",
      "\n",
      "Object number 179 is the most positive object\n",
      "\n",
      "\n",
      "Top 3 features for positive log evidence are-\n",
      "The feature is- BILL_AMT3 having weight_bais_value = 2.85574846727 and evidence value of 0.701996066473\n",
      "The feature is- BILL_AMT6 having weight_bais_value = 3.71755830976 and evidence value of 0.494562522405\n",
      "The feature is- BILL_AMT2 having weight_bais_value = -0.729231522493 and evidence value of 0.360758230713\n",
      "\n",
      "The feature is- PAY_AMT2 having weight_bais_value = 16.6898901411 and evidence value of -4.39161892492\n",
      "The feature is- PAY_0 having weight_bais_value = -1.8023713132 and evidence value of -1.15260602701\n",
      "The feature is- BILL_AMT5 having weight_bais_value = 3.45178764043 and evidence value of -0.127812065419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ith=np.argmax(probDist[:,1])\n",
    "Final(ith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5.2- The most negative object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total positive evidence is: -0.169797177801\n",
      "\n",
      " Total negative evidence is: -2.85838732942\n",
      "\n",
      "probability distribution is: [ 1.  0.]\n",
      "\n",
      "Object number 0 is the most positive object\n",
      "\n",
      "\n",
      "Top 3 features for positive log evidence are-\n",
      "The feature is- BILL_AMT3 having weight_bais_value = 2.39588710702 and evidence value of 0.588953594518\n",
      "The feature is- BILL_AMT6 having weight_bais_value = 1.75998240593 and evidence value of 0.234137911376\n",
      "The feature is- PAY_2 having weight_bais_value = 1.76503211104 and evidence value of 0.180921894111\n",
      "\n",
      "The feature is- BILL_AMT2 having weight_bais_value = 2.11537157791 and evidence value of -1.04649577563\n",
      "The feature is- PAY_AMT2 having weight_bais_value = 0.790898012297 and evidence value of -0.208109379338\n",
      "The feature is- BILL_AMT5 having weight_bais_value = 2.22162329143 and evidence value of -0.0822617991134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ith=np.argmax(probDist[:,0])\n",
    "Final(ith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object with largest positive evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total positive evidence is: 7.45532105476\n",
      "\n",
      " Total negative evidence is: -5.02774034061\n",
      "\n",
      "probability distribution is: [ 1.  0.]\n",
      "\n",
      "Object number 5859 is the most positive object\n",
      "\n",
      "\n",
      "Top 3 features for positive log evidence are-\n",
      "The feature is- PAY_0 having weight_bais_value = 7.11544926369 and evidence value of 4.55028863706\n",
      "The feature is- BILL_AMT3 having weight_bais_value = 6.0744755245 and evidence value of 1.49321901875\n",
      "The feature is- BILL_AMT6 having weight_bais_value = 6.81540223604 and evidence value of 0.906681816452\n",
      "\n",
      "The feature is- BILL_AMT2 having weight_bais_value = 5.9745254433 and evidence value of -2.95565833592\n",
      "The feature is- BILL_AMT5 having weight_bais_value = 6.6659849547 and evidence value of -0.246826686303\n",
      "The feature is- LIMIT_BAL having weight_bais_value = 2.69253552888 and evidence value of -0.194603675477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ith=np.argmax(evidence_greaterThan0_positive)\n",
    "Final(ith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object with largest  (in magnitude) negative evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total positive evidence is: -0.220016645513\n",
      "\n",
      " Total negative evidence is: -32.7862732637\n",
      "\n",
      "probability distribution is: [ 1.  0.]\n",
      "\n",
      "Object number 8706 is the most positive object\n",
      "\n",
      "\n",
      "Top 3 features for positive log evidence are-\n",
      "The feature is- BILL_AMT6 having weight_bais_value = 3.80982059015 and evidence value of 0.506836564212\n",
      "The feature is- BILL_AMT3 having weight_bais_value = 1.8523726905 and evidence value of 0.455347646081\n",
      "The feature is- EDUCATION having weight_bais_value = -1.0872212631 and evidence value of 0.0911991785504\n",
      "\n",
      "The feature is- PAY_AMT2 having weight_bais_value = 56.9293853091 and evidence value of -14.979856895\n",
      "The feature is- PAY_AMT3 having weight_bais_value = 56.2247912023 and evidence value of -7.84394453316\n",
      "The feature is- PAY_AMT4 having weight_bais_value = 55.8953334387 and evidence value of -3.28237070094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ith=np.absolute(np.argmin(evidence_lessThan0_negative))\n",
    "Final(ith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most uncertain object (probs~0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total positive evidence is: -0.169797177801\n",
      "\n",
      " Total negative evidence is: -2.85838732942\n",
      "\n",
      "probability distribution is: [ 1.  0.]\n",
      "\n",
      "Object number 0 is the most positive object\n",
      "\n",
      "\n",
      "Top 3 features for positive log evidence are-\n",
      "The feature is- BILL_AMT3 having weight_bais_value = 2.39588710702 and evidence value of 0.588953594518\n",
      "The feature is- BILL_AMT6 having weight_bais_value = 1.75998240593 and evidence value of 0.234137911376\n",
      "The feature is- PAY_2 having weight_bais_value = 1.76503211104 and evidence value of 0.180921894111\n",
      "\n",
      "The feature is- BILL_AMT2 having weight_bais_value = 2.11537157791 and evidence value of -1.04649577563\n",
      "The feature is- PAY_AMT2 having weight_bais_value = 0.790898012297 and evidence value of -0.208109379338\n",
      "The feature is- BILL_AMT5 having weight_bais_value = 2.22162329143 and evidence value of -0.0822617991134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p=probDist[:,0]\n",
    "# print(p)\n",
    "n=probDist[:,1]\n",
    "# print(n)\n",
    "sub=np.subtract(p,n)\n",
    "# print(sub)\n",
    "absolute=np.absolute(sub)\n",
    "# print(absolute)\n",
    "ith=np.argmin(absolute)\n",
    "# print(ith)\n",
    "Final(ith)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
